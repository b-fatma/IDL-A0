{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MLv5umNlCkcy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "#given that x is activated\n",
        "def sigmoid_prime(x):\n",
        "  return x * (1 - x)"
      ],
      "metadata": {
        "id": "9d3Ae-QyCmvt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def xor_net(inputs: list[2], weights: list[list[3]]):\n",
        "  net = {}\n",
        "\n",
        "  # calculate activations\n",
        "  hidden_node1 = sigmoid(weights[0][0] * inputs[0] + weights[0][1] * inputs[1] + weights[0][2])\n",
        "  hidden_node2 = sigmoid(weights[1][0] * inputs[0] + weights[1][1] * inputs[1] + weights[1][2])\n",
        "\n",
        "  output_node = sigmoid(weights[2][0] * hidden_node1 + weights[2][1] * hidden_node2 + weights[2][2])\n",
        "\n",
        "  # save activated values\n",
        "  net['h1'] = hidden_node1\n",
        "  net['h2'] = hidden_node2\n",
        "  net['output'] = output_node\n",
        "\n",
        "  return net"
      ],
      "metadata": {
        "id": "Iunpf6g_C9DT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(weights):\n",
        "  inputs = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
        "  targets = [0, 1, 1, 0]\n",
        "  total_error = 0\n",
        "\n",
        "  for i in range(len(inputs)):\n",
        "    predicted = xor_net(inputs[i], weights)[\"output\"]\n",
        "    total_error += (targets[i] - predicted) ** 2\n",
        "\n",
        "  return total_error / len(inputs)"
      ],
      "metadata": {
        "id": "j-mlQb46Dz4k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grdmse(weights):\n",
        "    inputs = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
        "    targets = [0, 1, 1, 0]\n",
        "\n",
        "    gradient = [np.zeros_like(w) for w in weights]  # initialize gradient with zeros\n",
        "\n",
        "    for i in range(len(inputs)):\n",
        "        net_info = xor_net(inputs[i], weights)\n",
        "        output_node = net_info['output']\n",
        "        hidden_node1 = net_info['h1']\n",
        "        hidden_node2 = net_info['h2']\n",
        "\n",
        "        # partial derivatives of MSE with respect to each weight (negative)\n",
        "        d_error_d_output = 2 * (targets[i] - output_node)\n",
        "        d_output_d_net_output = sigmoid_prime(output_node)\n",
        "\n",
        "        # output layer weights\n",
        "        gradient[2][0] += d_error_d_output * d_output_d_net_output * hidden_node1\n",
        "        gradient[2][1] += d_error_d_output * d_output_d_net_output * hidden_node2\n",
        "        gradient[2][2] += d_error_d_output * d_output_d_net_output\n",
        "\n",
        "        # hidden layer weights\n",
        "        d_net_output_d_hidden1 = weights[2][0]\n",
        "        d_net_output_d_hidden2 = weights[2][1]\n",
        "\n",
        "        gradient[0][0] += (\n",
        "            d_error_d_output\n",
        "            * d_output_d_net_output\n",
        "            * d_net_output_d_hidden1\n",
        "            * sigmoid_prime(hidden_node1)\n",
        "            * inputs[i][0]\n",
        "        )\n",
        "        gradient[0][1] += (\n",
        "            d_error_d_output\n",
        "            * d_output_d_net_output\n",
        "            * d_net_output_d_hidden1\n",
        "            * sigmoid_prime(hidden_node1)\n",
        "            * inputs[i][1]\n",
        "        )\n",
        "        gradient[0][2] += (\n",
        "            d_error_d_output\n",
        "            * d_output_d_net_output\n",
        "            * d_net_output_d_hidden1\n",
        "            * sigmoid_prime(hidden_node1)\n",
        "        )\n",
        "\n",
        "        gradient[1][0] += (\n",
        "            d_error_d_output\n",
        "            * d_output_d_net_output\n",
        "            * d_net_output_d_hidden2\n",
        "            * sigmoid_prime(hidden_node2)\n",
        "            * inputs[i][0]\n",
        "        )\n",
        "        gradient[1][1] += (\n",
        "            d_error_d_output\n",
        "            * d_output_d_net_output\n",
        "            * d_net_output_d_hidden2\n",
        "            * sigmoid_prime(hidden_node2)\n",
        "            * inputs[i][1]\n",
        "        )\n",
        "        gradient[1][2] += (\n",
        "            d_error_d_output\n",
        "            * d_output_d_net_output\n",
        "            * d_net_output_d_hidden2\n",
        "            * sigmoid_prime(hidden_node2)\n",
        "        )\n",
        "\n",
        "    # the average gradient over all training samples\n",
        "    for i in range(len(gradient)):\n",
        "        gradient[i] /= len(inputs)\n",
        "\n",
        "    return gradient\n"
      ],
      "metadata": {
        "id": "R8kq8rKgI0Wz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_neural_network(weights, inputs, targets, learning_rate, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    misclassified_count = 0\n",
        "\n",
        "    for i in range(len(inputs)):\n",
        "      net_info = xor_net(inputs[i], weights)\n",
        "      output_node = net_info['output']\n",
        "      hidden_node1 = net_info['h1']\n",
        "      hidden_node2 = net_info['h2']\n",
        "\n",
        "      gradient = grdmse(weights)\n",
        "\n",
        "      for j in range(len(weights)):\n",
        "        weights[j] += learning_rate * gradient[j]\n",
        "\n",
        "      predicted = 1 if output_node > 0.5 else 0\n",
        "      if predicted != targets[i]:\n",
        "          misclassified_count += 1\n",
        "\n",
        "    if misclassified_count == 0:\n",
        "      break\n",
        "  print(f'Trained for {epoch} epochs, final mse {mse(weights)}')\n",
        ""
      ],
      "metadata": {
        "id": "nRYuSovSWCBS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_neural_network(weights, test_inputs, test_targets):\n",
        "    misclassified = 0\n",
        "    for i in range(len(test_inputs)):\n",
        "        net_info = xor_net(test_inputs[i], weights)\n",
        "        output_node = net_info['output']\n",
        "\n",
        "        #interpret output\n",
        "        predicted = 1 if output_node > 0.5 else 0\n",
        "\n",
        "        if predicted != test_targets[i]:\n",
        "            misclassified += 1\n",
        "\n",
        "    accuracy = 1 - (misclassified / len(test_inputs))\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "WeFObt4BXaRn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
        "targets = [0, 1, 1, 0]\n",
        "\n",
        "random.seed(43)\n",
        "weights = [[random.random() for _ in range(3)] for _ in range(3)]\n",
        "\n",
        "print(f\"The initial weights are: {weights}\")\n",
        "\n",
        "learning_rate = 0.5\n",
        "print(f\"The learning rate is: {learning_rate}\")\n",
        "\n",
        "\n",
        "epochs = 10000 #maximum number of iterations\n",
        "\n",
        "train_neural_network(weights, inputs, targets, learning_rate, epochs)\n",
        "print(f\"The final weights are: {weights}\")\n",
        "\n",
        "accuracy = test_neural_network(weights, inputs, targets)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdZBUULHI1QE",
        "outputId": "c8ffc38f-7487-43c3-b35a-e28e6c42d670"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The initial weights are: [[0.038551839337380045, 0.6962243226370528, 0.14393322139536102], [0.46253225482908755, 0.671646764117767, 0.7929512716552943], [0.45318922846621235, 0.4982722297980512, 0.01915710802434778]]\n",
            "The learning rate is: 0.5\n",
            "Trained for 400 epochs, final mse 0.12989346643136518\n",
            "The final weights are: [array([ 1.07013135,  1.41475086, -1.33359191]), array([ 4.13721731,  4.35236667, -0.90811219]), array([-2.90725016,  4.16408344, -1.96128866])]\n",
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3075 iterations.\n",
        "LR = 0.1. Seed 43\n",
        "\n",
        "160 iterations.\n",
        "LR = 1. Seed 0\n",
        "\n",
        "40 iterations.\n",
        "LR = 10. Seed 0\n",
        "\n",
        "400 iterations.\n",
        "LR = 0.5. Seed 0"
      ],
      "metadata": {
        "id": "tCen0WXwPwnW"
      }
    }
  ]
}